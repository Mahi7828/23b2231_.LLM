{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7224a0cf-d7cc-444e-a7c7-46723f20344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4eaa17b-af41-4acf-b4c7-7a54b71e3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=\"sk-proj-INTJGxHzWPvrrvIzjo74T3BlbkFJ8HXGcVxcHKAT1di61JkN\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582c414d-48f9-4481-9362-9ffd7b42571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_assistant(thread, run):\n",
    "    \"\"\"\n",
    "        Function to periodically check run status of AI assistant and print run time\n",
    "    \"\"\"\n",
    "\n",
    "    # wait for assistant process prompt\n",
    "    t0 = time.time()\n",
    "    while run.status != 'completed':\n",
    "\n",
    "        # retreive status of run (this might take a few seconds or more)\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "          thread_id=thread.id,\n",
    "          run_id=run.id\n",
    "        )\n",
    "\n",
    "        # wait 0.5 seconds\n",
    "        time.sleep(0.25)\n",
    "    dt = time.time() - t0\n",
    "    print(\"Elapsed time: \" + str(dt) + \" seconds\")\n",
    "    \n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc04650-5bbd-4274-b8cf-6afbd28a8dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_xIGCZbiTtoECFvrVTv6HbksL', created_at=1719056766, description='Data scientist GPT for YouTube comments', instructions=\"MahiGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. It reacts to feedback aptly and concludes with its signature '–MahiGPT'. MahiGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, thus keeping the interaction natural and engaging.\", metadata={}, model='gpt-3.5-turbo', name='MahiGPT', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "intstructions_string = \"MahiGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. \\\n",
    "It reacts to feedback aptly and concludes with its signature '–MahiGPT'. \\\n",
    "MahiGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\"\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"MahiGPT\",\n",
    "    description=\"Data scientist GPT for YouTube comments\",\n",
    "    instructions=intstructions_string,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe774cb3-e2d6-48b5-ad49-c08d5967501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()\n",
    "\n",
    "# generate user message\n",
    "user_message = \"Great content, thank you!\"\n",
    "\n",
    "# add a user message to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=user_message\n",
    ")\n",
    "\n",
    "# send message to assistant to generate a response\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f640784-1216-4ac0-b510-79653533f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for assistant process prompt\n",
    "run = wait_for_assistant(thread, run)\n",
    "\n",
    "# view run object (in Jupyter Lab)\n",
    "dict(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd6d74-de25-42cc-a55f-7a1542d65e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view messages added to thread\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2e252-dea3-496c-862b-f9452a877c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.beta.assistants.delete(assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d89e71-7388-4bad-8c42-4aedb4fc56b9",
   "metadata": {},
   "source": [
    "Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fcb25-3b94-41bd-9e7c-a5352702fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "intstructions_string_few_shot = \"\"\"MahiGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. \\\n",
    "It reacts to feedback aptly and concludes with its signature '–MahiGPT'. \\\n",
    "ShawGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\n",
    "\n",
    "Here are examples of ShawGPT responding to viewer comments.\n",
    "\n",
    "Viewer comment: This was a very thorough introduction to LLMs and answered many questions I had. Thank you.\n",
    "ShawGPT: Great to hear, glad it was helpful :) -MahiGPT\n",
    "\n",
    "Viewer comment: Epic, very useful for my BCI class\n",
    "ShawGPT: Thanks, glad to hear! -MahiGPT\n",
    "\n",
    "Viewer comment: Honestly the most straightforward explanation I've ever watched. Super excellent work Shaw. Thank you. It's so rare to find good communicators like you!\n",
    "ShawGPT: Thanks, glad it was clear -MahiGPT\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055d5d4-2fe2-42c4-bb99-2c6e620659ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"MahiGPT\",\n",
    "    description=\"Data scientist GPT for YouTube comments\",\n",
    "    instructions=intstructions_string_few_shot,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2312b-03a9-4c6c-832c-fed9d6674685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# generate technical question\n",
    "user_message = \"Great content, thank you!\"\n",
    "\n",
    "# add a user message to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=user_message\n",
    ")\n",
    "\n",
    "# send message to assistant to generate a response (this might take a few seconds or more)\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "# wait for assistant process prompt\n",
    "run = wait_for_assistant(thread, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee3a20-6d4b-4419-ba9a-65db0535c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print assistant response \n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26acb74c-10e0-40b8-a8f8-5aaa0ffe93cb",
   "metadata": {},
   "source": [
    "RAG\n",
    "Add docs for retrieval of information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96ee2c-c8bf-4b90-acd1-0d1ae28ccb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file (note: this will create a presisting file for your openai account, so be mindful about how many times you run this. \n",
    "# You can delete unnecessary files in the \"Files\" tab of your openai account. \n",
    "\n",
    "file = client.files.create(\n",
    "  file=open(\"articles/4 Ways to Quantify Fat Tails with Python _ by Shaw Talebi _ Towards Data Science.pdf\", \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbed419-cbbc-40ee-a94e-64c21ad2478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create new assistants with access to docs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2530665c-b844-4411-8ddd-65f74d1618ec",
   "metadata": {},
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"MahiGPT\",\n",
    "    description=\"Data scientist GPT for YouTube comments\",\n",
    "    instructions=intstructions_string_few_shot,\n",
    "    tools=[{\"type\": \"retrieval\"}],\n",
    "    file_ids=[file.id],\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e484798-8df0-4d47-bebc-015e2ec1bd59",
   "metadata": {},
   "source": [
    "Technical question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808394c-206f-4de7-af7c-a33d7035e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# generate technical question\n",
    "user_message = \"What is fat-tailedness?\"\n",
    "\n",
    "# add a user message to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=user_message\n",
    ")\n",
    "\n",
    "# send message to assistant to generate a response (this might take a several seconds or more)\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "# wait for assistant process prompt\n",
    "run = wait_for_assistant(thread, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938347c-4629-4270-9f1f-f965ccb5e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print assistant response \n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a105bbc-d080-41dc-82e9-a00819f0acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete assistant\n",
    "client.beta.assistants.delete(assistant.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(conda_env)",
   "language": "python",
   "name": "conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
